{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bright-offer",
   "metadata": {
    "id": "bright-offer"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "# Exercise 02 Notebook - Convolutional Neural Networks\n",
    "\n",
    "In this exercise we'll implement different convolutional neural networks, that is AlexNet and ResNet18. Further, we'll use a pretrained model and finetune it to further increase the performance.\n",
    "\n",
    "1. Load Data\n",
    "2. Implement AlexNet from Scratch\n",
    "3. Implement ResNet18 from Scratch\n",
    "4. Implement pretrained ResNet18\n",
    "5. Implement and finetune a pretrained ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-palmer",
   "metadata": {
    "id": "assisted-palmer"
   },
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We'll use the Imagenette data set during this exercise. More specifically, we'll use the Imagenette-320 data set. Imagenette is a very small subset of the Imagenet data set which consists of 9469 training samples and 3925 validation examples. Each sample is a 320x320 image, associated with a label from 10 different classes. More information can be found [here](https://github.com/fastai/imagenette)\n",
    "\n",
    "You can download the dataset [here](https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz)\n",
    "\n",
    "Labels:</br>\n",
    "0=n01440764='tench',</br>\n",
    "1=n02102040='English springer',</br>\n",
    "2=n02979186='cassette player',</br>\n",
    "3=n03000684='chain saw',</br>\n",
    "4=n03028079='church',</br>\n",
    "5=n03394916='French horn',</br>\n",
    "6=n03417042='garbage truck',</br>\n",
    "7=n03425413='gas pump',</br>\n",
    "8=n03445777='golf ball',</br>\n",
    "9=n03888257='parachute'</br>\n",
    "\n",
    "Task 1: Download the data set and create a *torch.utils.data.Dataset* class for training and validation set, respectively. </br>\n",
    "*Hint1 : You can use PyTorch's [ImageFolder](https://pytorch.org/vision/stable/datasets.html#imagefolder) class to create a torch.utils.data.Dataset*.</br>\n",
    "*Hint2: You need to transform each sample such that each image is of size 224 and each image needs to be a tensor. Use PyTorch's [transforms method](https://pytorch.org/vision/stable/transforms.html#torchvision-transforms)* </br>\n",
    "*Hint3: Enable GPU runtime as follows: Runtime > Change Runtime type > Hardware accelerator > GPU*\n",
    "\n",
    "Task 2: Create a DataLoader object with batch size = 8 for training and valid set, respectively<br>\n",
    "* *Hint: Don't forget to shuffle the DataLoader!* </br>\n",
    "\n",
    "Task 3: Print the shape of one batch (images and labels) and plot one example with image and label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-vehicle",
   "metadata": {
    "id": "protected-vehicle"
   },
   "source": [
    "### Download and unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-avenue",
   "metadata": {
    "id": "textile-avenue"
   },
   "outputs": [],
   "source": [
    "!wget -q https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\n",
    "!tar zxf /content/imagenette2-320.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6y_wVLQMntVn",
   "metadata": {
    "id": "6y_wVLQMntVn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XbXTJAWInyff",
   "metadata": {
    "id": "XbXTJAWInyff"
   },
   "source": [
    "### 1.1 Create DataSet (Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-1vfiuUVn255",
   "metadata": {
    "id": "-1vfiuUVn255"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-algorithm",
   "metadata": {
    "id": "fundamental-algorithm"
   },
   "source": [
    "### 1.2 Create DataLoader (Task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-packet",
   "metadata": {
    "id": "conventional-packet"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-tuner",
   "metadata": {
    "id": "sufficient-tuner"
   },
   "source": [
    "### 1.3 One Example (Task 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-healing",
   "metadata": {
    "id": "incorrect-healing"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "logical-department",
   "metadata": {
    "id": "logical-department"
   },
   "source": [
    "## 2. AlexNet Model from Scratch\n",
    "\n",
    "We introduced [AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) in the lecture. We now want to implement AlexNet from scratch using almost the same architecture as the authors proposed in the original paper and in the ImageNet Large Scale Visual Recognition Competition (ILSVRC)\n",
    "\n",
    "Task 4: Create a AlexNetFashionCNN class with 5 Convolutional Layers, 3 Pooling Layers and 2 fully connected-layers.\n",
    "* First convolutional layer: Kernel size: 11x11, stride:4, padding=2, check the number of input/output channels yourself\n",
    "* First max pooling layer: Window size: 3x3, stride:2\n",
    "* Second conv layer: Kernel size: 5x5, stride=1, padding:2, check the number of input/output channels: yourself\n",
    "* Second max pooling layer: Window size: 3x3, stride:2\n",
    "* Third conv layer: Kernel size: 3x3, stride=1, padding=1, check the number of input/output channels: yourself\n",
    "* Fourth conv layer: Kernel size: 3x3, stride=1, padding=1, check the number of input/output channels: yourself\n",
    "* Fifth conv layer: Kernel size: 3x3, stride=1, padding=1, check the number of input/output channels: yourself\n",
    "* Third max pooling layer: Window size: 3x3, stride=1\n",
    "* The ReLU non-linearity is applied to the output of every convolutional and fully-connected layer. (except for the last fully-connected layer!)\n",
    "* *Hint 1: Think about the output of the last layer. Should we apply an activation function? If yes, which one is most appropriate?\n",
    "* *Hint 2: What is the number of neurons in the first fully-connected layer? Try to figure it out by yourself!\n",
    "\n",
    "Task 5: Forward propagate the first batch to test whether the network is working as expected.\n",
    "\n",
    "Task 6: Implement a method which serves as a training loop to train the network\n",
    "* The method should expect the following parameters: the model which should be trained, number of epochs, and optimizer\n",
    "* The method should return the training and test accuracy of each epoch. Optionally, print the accuracy of training and validation for each epoch during training\n",
    "* This is actually the most difficult part, have a look at the other notebooks which we have already provided\n",
    "\n",
    "Task 7: Create an optimizer object (such as stochastic gradient descent), define the number of epochs and train the AlexNetFashionCNN\n",
    "* Play with the number of epochs, and the learning rate of the optimizer until you are satisfied with the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-fifteen",
   "metadata": {
    "id": "twenty-fifteen"
   },
   "source": [
    "### 2.1 AlexNetFashionCNN (Task 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-penalty",
   "metadata": {
    "id": "equivalent-penalty"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "serious-pizza",
   "metadata": {
    "id": "serious-pizza"
   },
   "source": [
    "### 2.2 Forward Propagation (first batch) (Task 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-commander",
   "metadata": {
    "id": "twenty-commander"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "obvious-webster",
   "metadata": {
    "id": "obvious-webster"
   },
   "source": [
    "### 2.3 Training Loop (Task 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-romania",
   "metadata": {
    "id": "important-romania"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fifth-ecuador",
   "metadata": {
    "id": "fifth-ecuador"
   },
   "source": [
    "### 2.4 Training (Task 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-reggae",
   "metadata": {
    "id": "boolean-reggae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dirty-cisco",
   "metadata": {
    "id": "dirty-cisco"
   },
   "source": [
    "## 3. ResNet18 from Scratch\n",
    "\n",
    "We introduced [ResNet18](https://arxiv.org/abs/1512.03385) in the lecture. Now, we want to build the ResNet18 model from scratch using the same architecture as in the original paper!\n",
    "\n",
    "Task 8: Instead of implementing the entire architecture yourself, you can use PyTorch's [torchvision-models](https://pytorch.org/vision/stable/models.html#torchvision-models) to download the architecture. Please don't use the pretrained model and explicitly set pretrained=False when using PyTorchs torchvison models.\n",
    "\n",
    "Task 9: Use the *fit method* defined above to train the ResNet18 model\n",
    "* Again, play with the optimizer and the number of epochs until you are satisfied with the results (in terms of accuracy on training and validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-promise",
   "metadata": {
    "id": "ready-promise"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "civil-memorabilia",
   "metadata": {
    "id": "civil-memorabilia"
   },
   "source": [
    "### 3.1 Create ResNet18 Model (Task 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-stack",
   "metadata": {
    "id": "painted-stack"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "breeding-cowboy",
   "metadata": {
    "id": "breeding-cowboy"
   },
   "source": [
    "### 3.2 ResNet18 Training (Task 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-diabetes",
   "metadata": {
    "id": "metropolitan-diabetes"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "starting-steering",
   "metadata": {
    "id": "starting-steering"
   },
   "source": [
    "## 4. Pretrained ResNet18\n",
    "\n",
    "In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\n",
    "\n",
    "Hence, we'll now use a ResNet18 model pretrained on ImageNet.\n",
    "\n",
    "Task 10: Download the ResNet18 architecture and weights from PyTorch, create a pretrained ResNet18 CNN, and replace the last fully-connected layer\n",
    "* Again, you can use PyTorch's [torchvision-models](https://pytorch.org/vision/stable/models.html#torchvision-models). But this time, set pretrained=True in order to download the weights from the pretrained model\n",
    "* *Hint: Note that the ResNet18 was pretrained on the ImageNet data set where the task was to classify 1000 different labels. Here we will only need 10 classes. Thus, you need to **replace** the last fully-connected layer with one which only produces 10 outputs instead of 1000.*\n",
    "\n",
    "Task 11: Use the *fit method* defined above to train the pretrained ResNet18 model\n",
    "* Again, play with the optimizer and the number of epochs until you are satisfied with the results (in terms of accuracy on training and validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-fellowship",
   "metadata": {
    "id": "operating-fellowship"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "virgin-produce",
   "metadata": {
    "id": "virgin-produce"
   },
   "source": [
    "### 4.1 Create Pretrained ResNet18 Model (Task 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-monitor",
   "metadata": {
    "id": "instructional-monitor"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "under-admission",
   "metadata": {
    "id": "under-admission"
   },
   "source": [
    "### 4.2 Pretrained ResNet18 Training (Task 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-cookbook",
   "metadata": {
    "id": "portuguese-cookbook"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "charged-tsunami",
   "metadata": {
    "id": "charged-tsunami"
   },
   "source": [
    "## 5. Finetuning Pretrained ResNet18\n",
    "\n",
    "In the previous exercise (Chapter 4), we retrained the entire pretrained ResNet18 model using the Imagenette data set. Although the results were already pretty good, it might be better to only train the custom, final fully-connected layer. Remember, that every layer in a pretrained model is already optimized except for the custom final fully-connected layer which is randomly initialized. Thus, in this exercise we want to **only train the custom fully-connected layer** (only update the weights of the custom fully-connected layer) and keep the other layers (and weigts).\n",
    "\n",
    "Task 12: Download the ResNet18 architecture and weights from PyTorch, create a pretrained ResNet18 CNN, freeze all layers, and replace the last fully-connected layer\n",
    "* *Hint 1: In order to \"freeze\" a layer, you need to set its requires_grad Parameter to False\n",
    "* *Hint 2: First freeze all layers, than add the custom, final fully-connected layer\n",
    "\n",
    "Task 13: Use the *fit method* defined above to train only the last layer of the pretrained ResNet18 model\n",
    "* Note how the training is much faster (as we don't need to compute the gradients for each layer!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-manual",
   "metadata": {
    "id": "differential-manual"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "athletic-petersburg",
   "metadata": {
    "id": "athletic-petersburg"
   },
   "source": [
    "### 5.1 Create Pretrained ResNet18 Model (Task 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-victoria",
   "metadata": {
    "id": "cleared-victoria"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "monthly-monster",
   "metadata": {
    "id": "monthly-monster"
   },
   "source": [
    "### 5.2 Pretrained ResNet18 Fine Tuning (Task 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-prague",
   "metadata": {
    "id": "million-prague"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [pipenv: aiim_env]",
   "language": "python",
   "name": "aiim_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
